{smcl}
{* *! version 1.0.0  10oct2016}{...}
{cmd:help calibrationbelt}{right: ({browse "http://www.stata-journal.com/article.html?article=gr0071":SJ17-4: gr0071})}
{vieweralsosee "[R] logit" "logit"}{...}
{viewerjumpto "Syntax" "calibrationbelt##syntax"}{...}
{viewerjumpto "Description" "calibrationbelt##description"}{...}
{viewerjumpto "Options" "calibrationbelt##options"}{...}
{viewerjumpto "Remarks" "calibrationbelt##remarks"}{...}
{viewerjumpto "Examples" "calibrationbelt##examples"}{...}
{viewerjumpto "Also see" "calibrationbelt##alsosee"}{...}
{hline}

{title:Title}

{p2colset 5 24 26 2}{...}
{p2col :{cmd:calibrationbelt} {hline 2}}Plot the calibration belt and compute the associated test to evaluate the calibration of binary outcome models{p_end}
{p2colreset}{...}


{marker syntax}{...}
{title:Syntax}

{p 8 23 2}
{cmdab:calibrationbelt}
[{varlist}]
[{it:if}]
[{cmd:,} {it:options}]

{synoptset 15}{...}
{synopthdr}
{synoptline}
{synopt:{opt devel(string)}}specify the type of calibration assessment: {cmd:internal} or {cmd:external}{p_end}
{synopt:{opt cLevel1(#)}}first confidence levels to be considered in the plot; default is {cmd:cLevel1(0.95)}{p_end}
{synopt:{opt cLevel2(#)}}second confidence level; default is {cmd:cLevel2(0.8)}{p_end}
{synopt:{opt nPoints(#)}}number of points used to plot the border of the confidence band; default is {cmd:nPoints(100)}{p_end}
{synopt:{opt maxDeg(#)}}maximum degree of the polynomial function used to evaluate the model; default is {cmd:maxDeg(4)}{p_end}
{synopt:{opt thres(#)}}threshold parameter involved in the construction of the polynomial function that is used to evaluate the model; default is {cmd:thres(0.95)}{p_end}
{synoptline}
{p2colreset}{...}
{p 4 6 2}
The option {opt devel(string)} is required whenever the user specifies
{it:varlist} or an {cmd:if} qualifier.


{marker description}{...}
{title:Description}

{pstd}
{cmd:calibrationbelt} generates the calibration belt plot and reports the
value of the associated statistical test.  The command can be used in two
ways.

{pstd}
First, the variables identifying the binary response and the predicted
probability of the outcome must be passed as an argument in {varlist}.  In
this case, the user must specify whether the predictions have been fit on the
dataset under evaluation ({cmd:devel("internal")}) or whether the assessment
consists in an external, independent validation ({cmd:devel("external")}).

{pstd}
Second, the command can be run after fitting a logistic regression model (see
{manhelp logit R} or {manhelp logistic R}) without specifying any variable in
{it:varlist}.  In this case, the program evaluates the calibration of the
model on the developmental data.  It is assumed that the analysis concerns the
assessment of internal calibration.


{marker options}{...}
{title:Options}

{phang}
{opt devel(string)} specifies whether the calibration is evaluated on the same
dataset used to fit the model ({cmd:devel("internal")}) or is evaluated on
external independent samples ({cmd:devel("external")}).  Depending on the use
of the command (see {it:Description} section), the program may force the user
to specify the setting.  See also the {it:Remarks} section for further
details.

{phang}
{opt cLevel1(#)} sets one of the confidence levels to be considered in the
calibration belt plot.  A second confidence level can be set with the argument
{opt cLevel2(#)}.  The defaults are {cmd:cLevel1(95)} and {cmd:cLevel2(80)}.
A single calibration belt (that is, a plot with a single confidence level) can
be generated by specifying only the first argument.  For example, setting
{cmd:cLevel1(0.99)} produces a single calibration belt with confidence level
99%.  A double calibration belt with customized pairs of confidence levels can
be produced by providing both optional arguments, {opt cLevel1(#)} and 
{opt cLevel2(#)}.

{phang}
{opt cLevel2(#)} see comments for {opt cLevel1(#)}.

{phang}
{opt nPoints(#)} specifies the number of points defining the edges of the
belt.  The default is {cmd:nPoints(100)}.  Reducing the number of points can
substantially speed up the production of the plot in large datasets.  However,
this number also affects the estimate of the probabilities where the belt
crosses the bisector (that is, the limits of the intervals reported in the
table on the plot).  Indeed, the greater the value of {cmd:nPoints()}, the
higher the precision in the estimate of these values.  If the production of
the belt is too slow, but the analysis requires an iterative construction of
many belts, for example, in exploratory analyses, a possible strategy is to
decrease the number of points to values much smaller than the default (say, 20
or 50), accounting for the larger uncertainty in the interpretation of the
plots.  Finally, when the analysis is set up, the number of points can be
increased to the default value to achieve more accurate estimates of the
potential deviations from the bisector.

{phang}
{opt maxDeg(#)} fixes the maximum degree of the polynomial function used to
evaluate the model.  The default is {cmd:maxDeg(4)}.  See the {it:Remarks}
section for further details.

{phang}
{opt thres(#)} sets the threshold parameter involved in the construction of
the polynomial function used to evaluate the model.  This parameter
corresponds to one minus the significance level used when testing the increase
of the polynomial order in the forward selection (see {it:Remarks} section for
further details).  The default is {cmd:thres(0.95)}, specifying a forward
selection ruled by a sequence of classic 0.05-level tests.  Greater values of
{cmd:thres()} correspond to more conservative scenarios, where low-order
polynomials are preferred to high-order ones.  Calibration belts based on
lower {cmd:thres()} values are more likely to be based on high-order
polynomials.


{marker remarks}{...}
{title:Remarks}

{pstd}
The calibration test is designed to assess the calibration of models
estimating the probability of binary responses.  The calibration belt and the
related test can be used to evaluate a model's performance both in external
samples and in the development dataset.  However, the two cases have different
requirements.  When a model is evaluated on independent samples, the
calibration belt and the related test can be applied to the result of any
predictive tool.  Conversely, the approach can be used on the development set
only in the case of logistic regression models.  See Nattino, Finazzi, and
Bertolini (2016) for further details.

{pstd}
The generation of the plot relies on two parameters set by the options
{cmd:maxDeg()} and {cmd:thres()}.  Extensive simulations evaluating the
sensitivity of the calibration belt and test to the choice of these parameters
have been carried out in Nattino, Finazzi, and Bertolini (2014).  We suggest
using the default values of {cmd:maxDeg(4)} and {cmd:thres(0.95)}.


{marker examples}{...}
{title:Examples}

{phang}{cmd:. use http://www.stata-press.com/data/r15/hospid2}{p_end}
{phang}{cmd:. logit low lwt i.race i.smoke}{p_end}
{phang}{cmd:. calibrationbelt}{p_end}

{phang}{cmd:. logit low lwt i.race i.smoke}{p_end}
{phang}{cmd:. predict phat, pr}{p_end}
{phang}{cmd:. calibrationbelt low phat, devel("internal")}{p_end}
{phang}{cmd:. calibrationbelt low phat, devel("internal") cLevel1(0.99) cLevel2(0.95)}{p_end}


{marker references}{...}
{title:References}

{phang}
Nattino, G., S. Finazzi, and G. Bertolini. 2014. A new calibration test and a 
reappraisal of the calibration belt for the assessment of prediction models
based on dichotomous outcomes. {it:Statistics in Medicine} 33: 2390-2407.

{phang}
------.  2016.  A new test and graphical tool to assess the goodness of fit of 
logistic regression models. {it:Statistics in Medicine} 35: 709-720.


{title:Authors}

{pstd}
Giovanni Nattino{break}
Division of Biostatistics{break}
College of Public Health{break}
The Ohio State University{break}
Columbus, OH{break}
nattino.1@osu.edu

{pstd}
Stanley Lemeshow{break}
Division of Biostatistics{break}
College of Public Health{break}
The Ohio State University{break}
Columbus, OH

{pstd}
Gary Phillips{break}
Center for Biostatistics{break}
The Department of Biomedical Informatics{break}
The Ohio State University{break}
Columbus, OH

{pstd}
Stefano Finazzi{break}
GiViTI Coordinating Center{break}
Laboratory of Clinical Epidemiology{break}
IRCCS Istituto di Ricerche Farmacologiche `Mario Negri'{break}
Ranica, Italy

{pstd}
Guido Bertolini{break}
GiViTI Coordinating Center{break}
Laboratory of Clinical Epidemiology{break}
IRCCS Istituto di Ricerche Farmacologiche `Mario Negri'{break}
Ranica,  Italy


{marker alsosee}{...}
{title:Also see}

{p 4 14 2}Article:  {it:Stata Journal}, volume 17, number 4: {browse "http://www.stata-journal.com/article.html?article=gr0071":gr0071}{p_end}
